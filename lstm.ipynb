{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "from platform import python_version\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "def data_generator(data):\n",
    "    h, w = data.shape\n",
    "    # print(h, w)\n",
    "\n",
    "    shape = (6,w)\n",
    "    new_data = sliding_window_view(data, shape)\n",
    "    n, *_ = new_data.shape\n",
    "    new_data = new_data.reshape((n,6,w))\n",
    "    return new_data\n",
    "\n",
    "def transform_data(arr):\n",
    "    x_arr = arr[:,:-1]\n",
    "    y_arr = arr[:,-1,-3]\n",
    "    return x_arr, y_arr\n",
    "\n",
    "#反标准化\n",
    "def inverse_label(data, width):\n",
    "    l, *_ = data.shape\n",
    "    data_trans = np.zeros((l, width))\n",
    "    data_trans[:,-3] = data.reshape((l))\n",
    "    data_trans = scaler.inverse_transform(data_trans)\n",
    "    return data_trans[:,-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0        time  activity  appCat.builtin  appCat.communication  \\\n",
      "27          12  2014-03-22  0.371361       25.241688             24.304156   \n",
      "28       16968  2014-03-23  0.217996       19.090643             34.981971   \n",
      "29       16983  2014-03-24  0.355413       26.189233             18.445960   \n",
      "30       17007  2014-03-25  0.274954       21.629851             30.290984   \n",
      "31       17031  2014-03-26  0.405049        8.758588             35.726369   \n",
      "32       17055  2014-03-27  0.356218       18.962623             54.889647   \n",
      "33       17077  2014-03-28  0.405412       10.331565             29.506020   \n",
      "34       17101  2014-03-29  0.397176       22.492611             23.053708   \n",
      "35       17125  2014-03-30  0.418194       14.227364             15.994000   \n",
      "36       17139  2014-03-31  0.383015       25.317161             38.086881   \n",
      "37       17163  2014-04-01  0.511297       11.200867             32.766246   \n",
      "38       17187  2014-04-02  0.469348       27.498537             25.513082   \n",
      "39       17211  2014-04-03  0.360561       15.295737             25.242992   \n",
      "40       17235  2014-04-04  0.543843       19.291074             71.662025   \n",
      "41       17259  2014-04-05  0.391632       23.506476             23.527182   \n",
      "42       17283  2014-04-06  0.303281        7.060589             26.984538   \n",
      "43       17307  2014-04-07  0.382308       16.462917             24.357817   \n",
      "44       17331  2014-04-08  0.230118       14.817529             30.764243   \n",
      "45       17355  2014-04-09  0.381734       17.164526             34.515738   \n",
      "46       17379  2014-04-10  0.284126       35.899304             34.590824   \n",
      "47       17403  2014-04-11  0.345387        7.698296             58.284785   \n",
      "48       17427  2014-04-12  0.328347        8.750208             28.210043   \n",
      "49       17451  2014-04-13  0.362599       17.732483             44.004696   \n",
      "50       17475  2014-04-14  0.299607       23.203962             31.447106   \n",
      "51       17499  2014-04-15  0.319287       48.311967             27.281566   \n",
      "52       17523  2014-04-16  0.378467       14.613062             28.167679   \n",
      "53       17547  2014-04-17  0.479780       29.085660             46.956570   \n",
      "54       17571  2014-04-18  0.381460       16.906111             32.892416   \n",
      "55       17595  2014-04-19  0.344156        7.247875             21.412679   \n",
      "56       17619  2014-04-20  0.549430       14.234020             21.248854   \n",
      "57       17642  2014-04-21  0.411522        8.704083             28.627280   \n",
      "58       17666  2014-04-22  0.394619       34.179561             41.680170   \n",
      "59       17690  2014-04-23  0.237193       30.776602             52.270426   \n",
      "60       17714  2014-04-24  0.498066       19.710794             57.052629   \n",
      "61       17738  2014-04-25  0.382158       25.276680             26.546284   \n",
      "62       17762  2014-04-26  0.404864       12.967448             32.812864   \n",
      "63       17785  2014-04-27  0.367371       21.715268             29.060059   \n",
      "64       17807  2014-04-28  0.371761       18.387797             29.463813   \n",
      "65       17831  2014-04-29  0.373517       21.641189             22.683815   \n",
      "66       17855  2014-04-30  0.442553        8.146212             33.837146   \n",
      "67       17879  2014-05-01  0.365436       14.242738             42.948525   \n",
      "68       17903  2014-05-02  0.397778       12.996064             24.224903   \n",
      "69       17927  2014-05-03  0.566171       14.264313             14.236114   \n",
      "70       17951  2014-05-04  0.217949       13.008333             40.862672   \n",
      "\n",
      "    appCat.entertainment  appCat.finance  appCat.game  appCat.office  \\\n",
      "27             34.472524             NaN          NaN            NaN   \n",
      "28             40.168655             NaN          NaN            NaN   \n",
      "29            141.378500             NaN          NaN            NaN   \n",
      "30            349.089105             NaN          NaN            NaN   \n",
      "31            176.104500             NaN    44.975500            NaN   \n",
      "32            250.197688             NaN   112.320600            NaN   \n",
      "33            129.072250             NaN    40.708750            NaN   \n",
      "34             43.273313             NaN    48.831239            NaN   \n",
      "35             81.635179             NaN    41.472375            NaN   \n",
      "36            115.007719             NaN    56.278833            NaN   \n",
      "37             71.630500             NaN    25.299400     141.805000   \n",
      "38            193.617294             NaN    48.851600            NaN   \n",
      "39            138.098872             NaN    63.327600            NaN   \n",
      "40            166.872700             NaN    33.673667            NaN   \n",
      "41             22.935769             NaN    32.538385            NaN   \n",
      "42             81.867816             NaN    12.542333            NaN   \n",
      "43            111.914040             NaN          NaN            NaN   \n",
      "44             75.261900             NaN    26.547000            NaN   \n",
      "45             53.435000             NaN   115.422000            NaN   \n",
      "46             79.308857             NaN   519.859800            NaN   \n",
      "47                   NaN             NaN   144.919200            NaN   \n",
      "48            189.474222             NaN    75.313750            NaN   \n",
      "49            210.202077             NaN     9.416000            NaN   \n",
      "50              5.753667             NaN   214.537045            NaN   \n",
      "51             43.211000             NaN   100.190889     216.433600   \n",
      "52                   NaN             NaN    79.704667     136.556161   \n",
      "53             39.708000             NaN    59.456667      68.801645   \n",
      "54             29.424500             NaN          NaN     132.158222   \n",
      "55              5.035000             NaN    66.818000            NaN   \n",
      "56             59.694714             NaN    25.364500            NaN   \n",
      "57            119.733600             NaN          NaN            NaN   \n",
      "58             85.550250             NaN          NaN      79.785000   \n",
      "59             60.656750             NaN    95.816667      50.576735   \n",
      "60             15.710833             NaN     3.008000      72.160710   \n",
      "61             19.710000             NaN          NaN      42.412500   \n",
      "62             35.191333             NaN     1.010000       4.013000   \n",
      "63            131.797143             NaN          NaN            NaN   \n",
      "64             76.043714             NaN   480.443667     186.732714   \n",
      "65             64.356031             NaN          NaN            NaN   \n",
      "66             52.240154             NaN          NaN            NaN   \n",
      "67             64.590914             NaN          NaN            NaN   \n",
      "68             70.565000             NaN          NaN     279.914909   \n",
      "69             29.680000             NaN          NaN            NaN   \n",
      "70             27.999200             NaN          NaN            NaN   \n",
      "\n",
      "    appCat.other  ...  appCat.travel  appCat.unknown  appCat.utilities  \\\n",
      "27     21.051571  ...            NaN       67.179690               NaN   \n",
      "28     16.645500  ...            NaN       54.863200         10.601000   \n",
      "29     23.353526  ...      39.085000       28.096400          3.016000   \n",
      "30     23.586000  ...      45.098000       32.120375               NaN   \n",
      "31     84.112000  ...      22.086000       21.333250               NaN   \n",
      "32     10.310111  ...      42.160000      476.958000               NaN   \n",
      "33      8.591333  ...       6.021000             NaN               NaN   \n",
      "34     10.224417  ...      14.029250       20.678167               NaN   \n",
      "35     17.512250  ...            NaN       27.274600         48.304000   \n",
      "36     13.855571  ...      34.179000        7.025000               NaN   \n",
      "37      7.130600  ...      59.922667       40.795700         35.176000   \n",
      "38     30.023333  ...      19.126381        9.618750         11.045000   \n",
      "39     17.547500  ...      51.079000       23.153333          4.011000   \n",
      "40      9.152000  ...      55.262000             NaN               NaN   \n",
      "41     21.294625  ...            NaN        6.761500               NaN   \n",
      "42     14.304000  ...      23.923000       11.766333               NaN   \n",
      "43      8.537500  ...      66.790400       22.587167               NaN   \n",
      "44     12.998375  ...      63.973500       21.288333          7.289250   \n",
      "45     12.486750  ...            NaN             NaN               NaN   \n",
      "46     18.223455  ...            NaN             NaN          2.006000   \n",
      "47     10.502857  ...      38.933095       72.438000               NaN   \n",
      "48     10.443563  ...      19.500000       37.556875               NaN   \n",
      "49     11.190615  ...            NaN       48.667333               NaN   \n",
      "50           NaN  ...      34.622800      102.507000               NaN   \n",
      "51     33.674286  ...      39.047500             NaN               NaN   \n",
      "52     11.050462  ...      52.088333             NaN               NaN   \n",
      "53     31.913062  ...      31.186000       31.163600               NaN   \n",
      "54     13.095923  ...       6.017000       19.994250         83.480000   \n",
      "55      9.571857  ...            NaN       48.516250          8.029500   \n",
      "56     28.384833  ...            NaN       42.227000          7.056000   \n",
      "57     17.037909  ...            NaN        8.454000               NaN   \n",
      "58     12.866455  ...      42.101333        3.592000          2.755333   \n",
      "59     63.482182  ...       5.013000       48.716278               NaN   \n",
      "60     31.332167  ...      70.298000       32.746667               NaN   \n",
      "61     13.647286  ...            NaN       35.552500          5.520500   \n",
      "62     15.563500  ...      24.511000       31.579000               NaN   \n",
      "63     93.932667  ...      27.142500       10.896182         10.091000   \n",
      "64    168.184538  ...      46.751000        7.493000         11.099000   \n",
      "65     14.339125  ...            NaN        0.111000               NaN   \n",
      "66      9.624000  ...            NaN       14.065000               NaN   \n",
      "67      4.018000  ...      30.695667       40.877600         23.138000   \n",
      "68           NaN  ...      41.285000             NaN               NaN   \n",
      "69           NaN  ...            NaN             NaN               NaN   \n",
      "70           NaN  ...            NaN             NaN               NaN   \n",
      "\n",
      "    appCat.weather  call  circumplex.arousal  circumplex.valence  mood  \\\n",
      "27             NaN   NaN                0.00                1.00  7.00   \n",
      "28             NaN   1.0               -0.40                1.00  7.00   \n",
      "29             NaN   NaN               -0.20               -0.20  5.80   \n",
      "30             NaN   NaN               -0.40                0.60  6.20   \n",
      "31             NaN   1.0               -0.25                1.25  7.00   \n",
      "32             NaN   NaN                0.75                1.25  7.00   \n",
      "33             NaN   NaN                0.60                1.20  7.00   \n",
      "34             NaN   NaN                0.25                1.50  7.25   \n",
      "35             NaN   1.0                0.00                1.20  7.00   \n",
      "36             NaN   1.0               -0.25                1.50  7.50   \n",
      "37             NaN   NaN                0.00                2.00  7.50   \n",
      "38             NaN   1.0                0.50                1.00  7.00   \n",
      "39             NaN   1.0                0.50                1.00  7.00   \n",
      "40             NaN   1.0                1.00                1.00  7.00   \n",
      "41             NaN   1.0                0.75                1.00  6.50   \n",
      "42             NaN   1.0                0.00                0.60  7.00   \n",
      "43             NaN   1.0               -0.25                0.25  5.75   \n",
      "44             NaN   NaN                0.20                0.60  6.60   \n",
      "45             NaN   NaN               -0.40                1.20  7.20   \n",
      "46             NaN   NaN                0.00                0.80  7.00   \n",
      "47             NaN   1.0                0.40                1.00  7.00   \n",
      "48             NaN   NaN               -0.25                1.00  7.75   \n",
      "49             NaN   1.0                0.60                1.00  7.20   \n",
      "50             NaN   NaN                 NaN                 NaN   NaN   \n",
      "51             NaN   1.0                0.00                1.00  7.25   \n",
      "52             NaN   1.0                0.00                1.00  7.40   \n",
      "53             NaN   NaN                1.00                1.40  7.40   \n",
      "54             NaN   1.0                0.40                1.00  7.60   \n",
      "55             NaN   NaN                0.00                1.00  7.75   \n",
      "56             NaN   1.0                0.50                1.00  7.75   \n",
      "57             NaN   NaN               -0.40                1.00  7.20   \n",
      "58             NaN   1.0                0.20                0.40  6.20   \n",
      "59             NaN   1.0                0.00                1.00  7.00   \n",
      "60             NaN   1.0                0.00                1.00  7.40   \n",
      "61             NaN   1.0               -0.20                1.20  7.80   \n",
      "62             NaN   1.0               -0.50                1.00  7.50   \n",
      "63             NaN   1.0               -0.20                1.00  7.00   \n",
      "64             NaN   1.0               -0.20                1.00  7.60   \n",
      "65             NaN   1.0               -0.20                1.20  7.40   \n",
      "66             NaN   1.0               -1.00                1.00  9.00   \n",
      "67             NaN   NaN                 NaN                 NaN   NaN   \n",
      "68             NaN   NaN                 NaN                 NaN   NaN   \n",
      "69             NaN   NaN                 NaN                 NaN   NaN   \n",
      "70             NaN   NaN                 NaN                 NaN   NaN   \n",
      "\n",
      "        screen  sms  \n",
      "27   59.186333  1.0  \n",
      "28  253.175559  NaN  \n",
      "29   46.077980  NaN  \n",
      "30  114.873898  NaN  \n",
      "31   59.343422  1.0  \n",
      "32  102.508034  NaN  \n",
      "33   46.488958  NaN  \n",
      "34   40.116553  NaN  \n",
      "35   37.993743  NaN  \n",
      "36   73.334544  NaN  \n",
      "37   48.954473  NaN  \n",
      "38   61.435870  1.0  \n",
      "39   52.301817  NaN  \n",
      "40  102.162786  1.0  \n",
      "41   33.732948  NaN  \n",
      "42   35.845757  NaN  \n",
      "43   49.857194  1.0  \n",
      "44  106.569672  NaN  \n",
      "45   48.387526  NaN  \n",
      "46  124.544393  1.0  \n",
      "47   54.714377  NaN  \n",
      "48   53.353968  NaN  \n",
      "49   76.238580  NaN  \n",
      "50   67.399145  NaN  \n",
      "51   61.791358  NaN  \n",
      "52   58.097646  NaN  \n",
      "53   64.910620  NaN  \n",
      "54   52.806303  NaN  \n",
      "55   25.826196  NaN  \n",
      "56   35.058204  NaN  \n",
      "57   38.586932  NaN  \n",
      "58   94.314308  NaN  \n",
      "59   68.623438  NaN  \n",
      "60   80.694824  1.0  \n",
      "61   44.595633  NaN  \n",
      "62   41.612545  NaN  \n",
      "63   50.740810  1.0  \n",
      "64   88.443127  1.0  \n",
      "65   41.342071  NaN  \n",
      "66   45.264237  NaN  \n",
      "67   60.863804  NaN  \n",
      "68   53.491383  NaN  \n",
      "69   18.451426  NaN  \n",
      "70   55.636265  NaN  \n",
      "\n",
      "[44 rows x 21 columns]\n",
      "(44, 18)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('per_person_data/out_AS14.23.csv')\n",
    "df = df.dropna(thresh=2, subset=['activity', 'call', 'mood', 'screen'])\n",
    "df = df.dropna(how='all', subset=['appCat.builtin', 'appCat.communication', 'appCat.entertainment', 'appCat.finance', 'appCat.game', 'appCat.office', 'appCat.travel', 'appCat.unknown', 'appCat.utilities', 'appCat.weather'])\n",
    "df = df.sort_values('time')\n",
    "print(df)\n",
    "df = df.fillna({'call':0,'sms':0, 'appCat.builtin':0, 'appCat.communication':0, 'appCat.unknown':0,\n",
    "       'appCat.entertainment':0, 'appCat.other':0, 'appCat.social':0, 'appCat.finance':0, 'appCat.game':0, 'appCat.office':0, 'appCat.travel':0, 'appCat.utilities':0, 'appCat.weather':0,  'appCat.weather':0})\n",
    "# df = df.drop(columns=['appCat.finance', 'appCat.game', 'appCat.office', 'appCat.travel', 'appCat.unknown', 'appCat.utilities', 'appCat.weather'])\n",
    "df = df.drop(columns=['appCat.unknown'])\n",
    "df = df.fillna(df.median(numeric_only=True))\n",
    "# print(df.shape)\n",
    "# df.drop_duplicates(subset=['time'])\n",
    "df = df.iloc[: , 1:]\n",
    "df_no_time = df.select_dtypes(include=['int64','float64'])\n",
    "print(df_no_time.shape)\n",
    "# print(df_no_time)\n",
    "# df_no_time.columns\n",
    "data = df_no_time.to_numpy()\n",
    "# data = df_no_time.to_numpy()\n",
    "# # print(data)\n",
    "# h, w = data.shape\n",
    "# # print(h, w)\n",
    "\n",
    "# shape = (6,w)\n",
    "# new_data = sliding_window_view(data, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Scaling \n",
    "# Fill in nan with all dataset's median\n",
    "from sklearn.impute import SimpleImputer\n",
    "empty = []\n",
    "all_data = np.array(empty)\n",
    "\n",
    "files = sorted(glob.glob('per_person_data/*.csv'))\n",
    "# files = sorted(glob.glob('test/*.csv'))\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    df = df.dropna(thresh=2, subset=['activity', 'call', 'mood', 'screen'])\n",
    "    df = df.dropna(how='all', subset=['appCat.builtin', 'appCat.communication', 'appCat.entertainment', 'appCat.finance', 'appCat.game', 'appCat.office', 'appCat.travel', 'appCat.unknown', 'appCat.utilities', 'appCat.weather'])\n",
    "    df = df.sort_values('time')\n",
    "    # df = df.fillna({'call':0,'sms':0})\n",
    "    # df = df.dropna(thresh=int(0.5*len(df)), axis=1)\n",
    "    df = df.fillna({'call':0,'sms':0, 'appCat.builtin':0, 'appCat.communication':0, 'appCat.entertainment':0, 'appCat.other':0, 'appCat.social':0})\n",
    "    df = df.drop(columns=['appCat.finance', 'appCat.game', 'appCat.office', 'appCat.travel', 'appCat.unknown', 'appCat.utilities', 'appCat.weather'])\n",
    "    # df = df.fillna(df.mean(numeric_only=True))\n",
    "    df = df.iloc[: , 1:]\n",
    "    df_no_time = df.select_dtypes(include=['int64','float64'])\n",
    "    data = df_no_time.to_numpy()\n",
    "    \n",
    "    new_data = data_generator(data)\n",
    "    \n",
    "    if all_data.size == 0:\n",
    "        all_data = new_data\n",
    "    else:\n",
    "        all_data = np.concatenate((all_data, new_data), axis=0)    \n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "nsamples, nx, ny = all_data.shape\n",
    "all_data = all_data.reshape((nsamples*nx, ny))\n",
    "im = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "all_data = im.fit_transform(all_data)\n",
    "trans_data = scaler.fit_transform(all_data).reshape((nsamples, nx, ny))\n",
    "all_data = all_data.reshape((nsamples, nx, ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>appCat.builtin</th>\n",
       "      <th>appCat.communication</th>\n",
       "      <th>appCat.entertainment</th>\n",
       "      <th>appCat.other</th>\n",
       "      <th>appCat.social</th>\n",
       "      <th>circumplex.arousal</th>\n",
       "      <th>circumplex.valence</th>\n",
       "      <th>mood</th>\n",
       "      <th>screen</th>\n",
       "      <th>past_mood</th>\n",
       "      <th>past_mood_std</th>\n",
       "      <th>past_valence</th>\n",
       "      <th>past_valence_std</th>\n",
       "      <th>past_arousal</th>\n",
       "      <th>past_arousal_std</th>\n",
       "      <th>next_mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.096359</td>\n",
       "      <td>12.361731</td>\n",
       "      <td>38.598403</td>\n",
       "      <td>48.245667</td>\n",
       "      <td>12.069500</td>\n",
       "      <td>54.034429</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>65.742128</td>\n",
       "      <td>7.090000</td>\n",
       "      <td>0.417013</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.172047</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.316220</td>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.096359</td>\n",
       "      <td>12.361731</td>\n",
       "      <td>38.598403</td>\n",
       "      <td>48.245667</td>\n",
       "      <td>12.069500</td>\n",
       "      <td>54.034429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>65.742128</td>\n",
       "      <td>7.090000</td>\n",
       "      <td>0.417013</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.172047</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.316220</td>\n",
       "      <td>6.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.134050</td>\n",
       "      <td>14.269173</td>\n",
       "      <td>55.095526</td>\n",
       "      <td>53.024000</td>\n",
       "      <td>29.968875</td>\n",
       "      <td>75.141667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>153.665872</td>\n",
       "      <td>7.090000</td>\n",
       "      <td>0.417013</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.172047</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.316220</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.236880</td>\n",
       "      <td>7.781160</td>\n",
       "      <td>51.697063</td>\n",
       "      <td>46.662000</td>\n",
       "      <td>14.020429</td>\n",
       "      <td>36.636000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>47.613651</td>\n",
       "      <td>7.090000</td>\n",
       "      <td>0.417013</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.172047</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.316220</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.142741</td>\n",
       "      <td>12.134396</td>\n",
       "      <td>53.442031</td>\n",
       "      <td>31.448667</td>\n",
       "      <td>12.137167</td>\n",
       "      <td>50.046611</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>67.067644</td>\n",
       "      <td>7.090000</td>\n",
       "      <td>0.417013</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.172047</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.316220</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.115201</td>\n",
       "      <td>7.711316</td>\n",
       "      <td>34.320472</td>\n",
       "      <td>68.876900</td>\n",
       "      <td>16.845500</td>\n",
       "      <td>111.046204</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>300.399810</td>\n",
       "      <td>6.046667</td>\n",
       "      <td>0.245719</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.197934</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.502770</td>\n",
       "      <td>6.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.012704</td>\n",
       "      <td>8.545776</td>\n",
       "      <td>59.382943</td>\n",
       "      <td>62.347000</td>\n",
       "      <td>17.835750</td>\n",
       "      <td>50.259100</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>113.607750</td>\n",
       "      <td>5.926667</td>\n",
       "      <td>0.359413</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.139443</td>\n",
       "      <td>-0.446667</td>\n",
       "      <td>0.496365</td>\n",
       "      <td>8.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.103301</td>\n",
       "      <td>9.590398</td>\n",
       "      <td>37.238750</td>\n",
       "      <td>43.907571</td>\n",
       "      <td>27.891895</td>\n",
       "      <td>99.281685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>113.657683</td>\n",
       "      <td>6.016667</td>\n",
       "      <td>0.360247</td>\n",
       "      <td>0.196667</td>\n",
       "      <td>0.167465</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.153116</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.169354</td>\n",
       "      <td>6.452161</td>\n",
       "      <td>54.388125</td>\n",
       "      <td>68.369000</td>\n",
       "      <td>9.734000</td>\n",
       "      <td>198.880222</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>118.978033</td>\n",
       "      <td>6.490000</td>\n",
       "      <td>0.923255</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.405024</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.192901</td>\n",
       "      <td>14.776845</td>\n",
       "      <td>46.412278</td>\n",
       "      <td>37.174286</td>\n",
       "      <td>10.522000</td>\n",
       "      <td>75.390690</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>86.342245</td>\n",
       "      <td>6.610000</td>\n",
       "      <td>0.942550</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.445022</td>\n",
       "      <td>-0.616667</td>\n",
       "      <td>0.437924</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1241 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     activity  appCat.builtin  appCat.communication  appCat.entertainment  \\\n",
       "7    0.096359       12.361731             38.598403             48.245667   \n",
       "8    0.096359       12.361731             38.598403             48.245667   \n",
       "26   0.134050       14.269173             55.095526             53.024000   \n",
       "27   0.236880        7.781160             51.697063             46.662000   \n",
       "28   0.142741       12.134396             53.442031             31.448667   \n",
       "..        ...             ...                   ...                   ...   \n",
       "98   0.115201        7.711316             34.320472             68.876900   \n",
       "99   0.012704        8.545776             59.382943             62.347000   \n",
       "100  0.103301        9.590398             37.238750             43.907571   \n",
       "101  0.169354        6.452161             54.388125             68.369000   \n",
       "102  0.192901       14.776845             46.412278             37.174286   \n",
       "\n",
       "     appCat.other  appCat.social  circumplex.arousal  circumplex.valence  \\\n",
       "7       12.069500      54.034429           -0.250000            0.750000   \n",
       "8       12.069500      54.034429            0.000000            0.333333   \n",
       "26      29.968875      75.141667            0.200000            0.200000   \n",
       "27      14.020429      36.636000            0.600000            0.500000   \n",
       "28      12.137167      50.046611            0.200000            0.800000   \n",
       "..            ...            ...                 ...                 ...   \n",
       "98      16.845500     111.046204           -0.400000            0.000000   \n",
       "99      17.835750      50.259100           -0.600000            0.400000   \n",
       "100     27.891895      99.281685            0.000000            1.200000   \n",
       "101      9.734000     198.880222           -1.333333            1.000000   \n",
       "102     10.522000      75.390690           -0.800000           -0.400000   \n",
       "\n",
       "         mood      screen  past_mood  past_mood_std  past_valence  \\\n",
       "7    6.250000   65.742128   7.090000       0.417013      0.720000   \n",
       "8    6.333333   65.742128   7.090000       0.417013      0.720000   \n",
       "26   6.200000  153.665872   7.090000       0.417013      0.720000   \n",
       "27   6.400000   47.613651   7.090000       0.417013      0.720000   \n",
       "28   6.800000   67.067644   7.090000       0.417013      0.720000   \n",
       "..        ...         ...        ...            ...           ...   \n",
       "98   5.400000  300.399810   6.046667       0.245719      0.126667   \n",
       "99   6.200000  113.607750   5.926667       0.359413      0.166667   \n",
       "100  8.200000  113.657683   6.016667       0.360247      0.196667   \n",
       "101  7.000000  118.978033   6.490000       0.923255      0.436667   \n",
       "102  6.800000   86.342245   6.610000       0.942550      0.586667   \n",
       "\n",
       "     past_valence_std  past_arousal  past_arousal_std  next_mood  \n",
       "7            0.172047     -0.100000          0.316220   6.333333  \n",
       "8            0.172047     -0.100000          0.316220   6.200000  \n",
       "26           0.172047     -0.100000          0.316220   6.400000  \n",
       "27           0.172047     -0.100000          0.316220   6.800000  \n",
       "28           0.172047     -0.100000          0.316220   6.000000  \n",
       "..                ...           ...               ...        ...  \n",
       "98           0.197934     -0.500000          0.502770   6.200000  \n",
       "99           0.139443     -0.446667          0.496365   8.200000  \n",
       "100          0.167465     -0.666667          0.153116   7.000000  \n",
       "101          0.405024     -0.500000          0.281069   6.800000  \n",
       "102          0.445022     -0.616667          0.437924   7.000000  \n",
       "\n",
       "[1241 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Data Preprocessing & Feature Engineering Revamped\n",
    "USE ONLY FOR CONVENTIONAL ML\n",
    "'''\n",
    "\n",
    "df_all = pd.DataFrame() \n",
    "\n",
    "files = sorted(glob.glob('per_person_data/*.csv'))\n",
    "for f in files:\n",
    "    # Initial filtering & preprocessing\n",
    "    df = pd.read_csv(f)\n",
    "    df = df[df['mood'].notna()]\n",
    "    df = df.sort_values('time')\n",
    "    df.drop_duplicates(subset=['time'])\n",
    "    df = df.iloc[: , 1:] \n",
    "\n",
    "\n",
    "    # NOTE: Turn this on for extra features \n",
    "    if True:\n",
    "        days_back = 5\n",
    "        mood = np.array(df['mood'])\n",
    "        df['past_mood'] = [np.nan] * days_back + [np.mean(mood[i:i+days_back]) for i in range(len(mood) - days_back)]\n",
    "        df['past_mood_std'] = [np.nan] * days_back + [np.std(mood[i: i+days_back]) for i in range(len(mood) - days_back)]\n",
    "\n",
    "        valence = np.array(df['circumplex.valence'])\n",
    "        df['past_valence'] = [np.nan] * days_back + [np.mean(valence[i:i+days_back]) for i in range(len(valence) - days_back)]\n",
    "        df['past_valence_std'] = [np.nan] * days_back + [np.std(valence[i: i+days_back]) for i in range(len(valence) - days_back)]\n",
    "\n",
    "        arousal = np.array(df['circumplex.arousal'])\n",
    "        df['past_arousal'] = [np.nan] * days_back + [np.mean(arousal[i:i+days_back]) for i in range(len(arousal) - days_back)]\n",
    "        df['past_arousal_std'] = [np.nan] * days_back + [np.std(arousal[i: i+days_back]) for i in range(len(arousal) - days_back)]\n",
    "\n",
    "\n",
    "    df['next_mood'] = df['mood'].shift(periods=-1) # Create target variable\n",
    "    df = df[:-1]\n",
    "    df_all = pd.concat([df_all, df], axis=0) # NOTE: SLOW for large dataframes   \n",
    "\n",
    "df_all = df_all.drop(['time'], axis=1)\n",
    "# df_all = df_all.drop(['mood'], axis=1)\n",
    "\n",
    "\n",
    "for col in df_all.columns:\n",
    "    prc_nan = df_all[col].isnull().sum() / len(df_all[col])\n",
    "    \n",
    "    if prc_nan < .4:\n",
    "        df_all[col] = df_all[col].fillna(df_all[col].median())\n",
    "    else:\n",
    "        df_all = df_all.drop([col], axis=1)\n",
    "\n",
    "# data = df_all.to_numpy()\n",
    "# all_data = data_generator(data)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "nsamples, nx, ny = all_data.shape\n",
    "trans_data = all_data.reshape((nsamples*nx, ny))\n",
    "trans_data = scaler.fit_transform(trans_data).reshape((nsamples, nx, ny))\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, regularizers, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout, BatchNormalization\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from attention import Attention\n",
    "\n",
    "# divide dataset\n",
    "X, Y = transform_data(trans_data)\n",
    "\n",
    "#Generate indices on the row-wise length of the whole \n",
    "#array\n",
    "fold_indices = np.arange(X.shape[0])\n",
    "\n",
    "#Shuffle the indices -- if you want, but not \n",
    "#neccessary\n",
    "np.random.shuffle(fold_indices)\n",
    "\n",
    "k = 8\n",
    "#Split the indices into k-parts (returns a list of \n",
    "#numpy arrays)\n",
    "cross_validatoin_score = []\n",
    "test_all_x = np.array(empty)\n",
    "test_all_y = np.array(empty)\n",
    "eval_indices = np.array_split(fold_indices, k)\n",
    "for idx, e in enumerate(eval_indices):\n",
    "    #Define the evaluation set for the current fold\n",
    "    test_set_x = X[e]\n",
    "    test_set_y = Y[e]\n",
    "\n",
    "    #exclude the upon parts indices from the \n",
    "    #whole array (similarly on the upon answers)\n",
    "    \n",
    "    mask_eval = np.ones(X.shape[0], bool)\n",
    "    \n",
    "    #Set indices of the eval set to false\n",
    "    mask_eval[e] = False\n",
    "\n",
    "    #Subset by the bool array:\n",
    "    train_set_x = X[mask_eval].astype('float32')\n",
    "    train_set_y = Y[mask_eval].astype('float32')\n",
    "    print(f'Fold: {idx}')\n",
    "    print(f'Train set shape: {train_set_x.shape}    Test set shape: {test_set_x.shape}')\n",
    "    num_samples, time_steps, input_dim = train_set_x.shape\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(time_steps, input_dim)))\n",
    "    model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Bidirectional(LSTM(128,return_sequences=False)))\n",
    "    model.add(Dropout(rate=0.7))\n",
    "    # model.add(Attention(units=32))\n",
    "    # model.add(Dense(4,activation=\"tanh\",  kernel_regularizer=regularizers.l1(0.01)))\n",
    "    # model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(1,activation=\"tanh\",  kernel_regularizer=regularizers.l1(0.01)))\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=0.01, clipvalue=0.5)\n",
    "    model.compile(optimizer=optimizer,loss=\"mean_squared_error\", metrics=[\"mse\"])\n",
    "    model.fit(train_set_x,train_set_y,batch_size=32,epochs=7,validation_split=0.1,verbose=1)\n",
    "    # Evaluate the model on the test data using `evaluate`\n",
    "    print(\"Evaluate on test data\")\n",
    "    results = model.evaluate(test_set_x, test_set_y, batch_size=64)\n",
    "    # print(\"test loss, test acc:\", results)\n",
    "    cross_validatoin_score.append(results)\n",
    "\n",
    "    if test_all_x.size == 0:\n",
    "        test_all_x = test_set_x\n",
    "        test_all_y = test_set_y\n",
    "    else:\n",
    "        test_all_x = np.concatenate((test_all_x, test_set_x), axis=0)\n",
    "        test_all_y = np.concatenate((test_all_y, test_set_y), axis=0)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "_, _, w = train_set_x.shape\n",
    "#预测测试集\n",
    "# predict_trainY=model.predict(train_set_x)\n",
    "predict_testY=model.predict(test_set_x)\n",
    "#反标准化\n",
    "# trainY=scaler.inverse_transform(predict_trainY)\n",
    "testY_real = inverse_label(test_set_y[:,np.newaxis], w)\n",
    "testY_predict = inverse_label(predict_testY, w)\n",
    "# testY_real = Y_test\n",
    "# testY_predict = predict_testY\n",
    "print(model.summary())\n",
    "print(np.mean(np.array(cross_validatoin_score),axis=0))\n",
    "\n",
    "#看一看数据形状\n",
    "print(\"Y:\",testY_predict.reshape((-1)),testY_predict.shape)\n",
    "print(\"Y_real:\",testY_real,testY_real.shape)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(testY_predict,\"r\",label=\"Predict\")\n",
    "plt.plot(testY_real,\"b\",label=\"Real\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "predict_trainY=model.predict(train_set_x)\n",
    "#反标准化\n",
    "trainY_real = inverse_label(train_set_y[:,np.newaxis], w)\n",
    "trainY_predict = inverse_label(predict_trainY,w)\n",
    "\n",
    "#看一看数据形状\n",
    "# print(\"Y:\",trainY_predict.reshape((-1)),trainY_predict.shape)\n",
    "# print(\"Y_real:\",trainY_real,trainY_real.shape)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(trainY_real,\"b\",label=\"Real\")\n",
    "plt.plot(trainY_predict,\"r\",label=\"Predict\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross Validation scores: [-0.36513931 -0.32247513 -0.42611989 -0.34446178 -0.43493267 -0.47517793\n",
      " -0.30465195 -0.39567133]\n",
      "Average Cross Validation score :0.3835787493398479\n"
     ]
    }
   ],
   "source": [
    "# ML LR\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# divide dataset\n",
    "X, Y = df_all.iloc[:,:-1], df_all.iloc[:,-1]\n",
    "# nsamples, nx, ny = X.shape\n",
    "# X = X.reshape((nsamples,nx*ny))\n",
    "k = 8\n",
    "lr=LinearRegression()\n",
    "kf=KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "score=cross_val_score(lr,X,Y,cv=kf,scoring='neg_mean_squared_error')\n",
    "print(\"cross Validation scores: {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(np.negative(score.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross Validation scores: [-0.78866047 -1.20095175 -0.94805789 -0.50118238 -0.38778489 -0.62491104\n",
      " -0.71198182 -0.76102679]\n",
      "Average Cross Validation score :0.7405696288974254\n"
     ]
    }
   ],
   "source": [
    "# ML Rigid\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import RidgeCV\n",
    "# divide dataset\n",
    "X, Y = transform_data(trans_data)\n",
    "nsamples, nx, ny = X.shape\n",
    "X = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "ridge=RidgeCV(alphas=np.arange(1,1001,100))\n",
    "kf=KFold(n_splits=k)\n",
    "score=cross_val_score(ridge,X,Y,cv=kf,scoring='neg_mean_squared_error')\n",
    "print(\"cross Validation scores: {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(np.negative(score.mean())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/willem/Documents/CS/Data_Mining/DMT-ASM1/lstm.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/willem/Documents/CS/Data_Mining/DMT-ASM1/lstm.ipynb#ch0000007?line=6'>7</a>\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mreshape((nsamples,nx\u001b[39m*\u001b[39mny))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/willem/Documents/CS/Data_Mining/DMT-ASM1/lstm.ipynb#ch0000007?line=8'>9</a>\u001b[0m lasso\u001b[39m=\u001b[39mLassoCV()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/willem/Documents/CS/Data_Mining/DMT-ASM1/lstm.ipynb#ch0000007?line=9'>10</a>\u001b[0m kf\u001b[39m=\u001b[39mKFold(n_splits\u001b[39m=\u001b[39;49mk, shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/willem/Documents/CS/Data_Mining/DMT-ASM1/lstm.ipynb#ch0000007?line=10'>11</a>\u001b[0m score\u001b[39m=\u001b[39mcross_val_score(lasso,X,Y,cv\u001b[39m=\u001b[39mkf,scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/willem/Documents/CS/Data_Mining/DMT-ASM1/lstm.ipynb#ch0000007?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcross Validation scores: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(score))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py:435\u001b[0m, in \u001b[0;36mKFold.__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=433'>434</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, \u001b[39m*\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=434'>435</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(n_splits\u001b[39m=\u001b[39;49mn_splits, shuffle\u001b[39m=\u001b[39;49mshuffle, random_state\u001b[39m=\u001b[39;49mrandom_state)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py:296\u001b[0m, in \u001b[0;36m_BaseKFold.__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=292'>293</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mshuffle must be True or False; got \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(shuffle))\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=294'>295</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m shuffle \u001b[39mand\u001b[39;00m random_state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# None is the default\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=295'>296</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=296'>297</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSetting a random_state has no effect since shuffle is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=297'>298</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFalse. You should leave \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=298'>299</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrandom_state to its default (None), or set shuffle=True.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=299'>300</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=301'>302</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m=\u001b[39m n_splits\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py?line=302'>303</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshuffle \u001b[39m=\u001b[39m shuffle\n",
      "\u001b[0;31mValueError\u001b[0m: Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True."
     ]
    }
   ],
   "source": [
    "# ML Lasso\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "# divide dataset\n",
    "X, Y = transform_data(trans_data)\n",
    "nsamples, nx, ny = X.shape\n",
    "X = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "lasso=LassoCV()\n",
    "kf=KFold(n_splits=k, shuffle=False, random_state=0)\n",
    "score=cross_val_score(lasso,X,Y,cv=kf,scoring='neg_mean_squared_error')\n",
    "print(\"cross Validation scores: {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(np.negative(score.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1241,)\n",
      "cross Validation scores: [-0.31964298 -0.39979828 -0.38949372 -0.4266173  -0.48596002 -0.30108396\n",
      " -0.33831627 -0.40304046]\n",
      "Average Cross Validation score :0.38299412508312575\n"
     ]
    }
   ],
   "source": [
    "# ML SVR\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# divide dataset\n",
    "trans_data = df_all.to_numpy()\n",
    "\n",
    "k = 8\n",
    "# divide dataset\n",
    "X, Y = trans_data[:,:-1], trans_data[:,-1]\n",
    "print(Y.shape)\n",
    "# nsamples, nx, ny = X.shape\n",
    "# X = X.reshape((nsamples,nx*ny))\n",
    "clf = SVR(kernel='linear')\n",
    "kf=KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "score=cross_val_score(clf,X,Y,cv=kf,scoring='neg_mean_squared_error')\n",
    "print(\"cross Validation scores: {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(np.negative(score.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross Validation scores: [-0.61314166 -0.63089991 -0.58751037 -0.62167102 -0.5721789  -0.55402909\n",
      " -0.57904142 -0.57310075]\n",
      "Average Cross Validation score :0.5914466398137868\n"
     ]
    }
   ],
   "source": [
    "# ML KNN\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# divide dataset\n",
    "X, Y = transform_data(trans_data)\n",
    "nsamples, nx, ny = X.shape\n",
    "X = X.reshape((nsamples,nx*ny))\n",
    "neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "kf=KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "score=cross_val_score(neigh,X,Y,cv=kf,scoring='neg_mean_absolute_error')\n",
    "print(\"cross Validation scores: {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(np.negative(score.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross Validation scores: [-0.42035397 -0.34562986 -0.41398744 -0.33686016 -0.40716167 -0.48270924\n",
      " -0.32012631 -0.4354917 ]\n",
      "Average Cross Validation score :0.3952900438441695\n"
     ]
    }
   ],
   "source": [
    "# ML RandomForestReg\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "X, Y = df_all.iloc[:,:-1], df_all.iloc[:,-1]\n",
    "# nsamples, nx, ny = X.shape\n",
    "# X = X.reshape((nsamples,nx*ny))\n",
    "regr = RandomForestRegressor(max_depth=3, random_state=0, n_estimators=50, criterion='squared_error')\n",
    "kf=KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "score=cross_val_score(regr,X,Y,cv=kf,scoring='neg_mean_squared_error')\n",
    "print(\"cross Validation scores: {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(np.negative(score.mean())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross Validation scores: [0.30177766 0.32141243 0.18194864 0.22270254 0.05735733 0.18233292\n",
      " 0.32411622 0.09671577]\n",
      "Average Cross Validation score :-0.21104543795391273\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBRegressor(max_depth = 4,\n",
    "                             learning_rate = 1e-1,\n",
    "                             n_estimators = 50,\n",
    "                             objective = 'reg:squarederror',\n",
    "                             n_jobs = -1)\n",
    "\n",
    "kf=KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "score=cross_val_score(xgb_model,X,Y,cv=kf,scoring='r2')\n",
    "print(\"cross Validation scores: {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(np.negative(score.mean())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "Y_train = Y_train.astype('float32')\n",
    "num_samples, time_steps, input_dim = X_train.shape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(time_steps, input_dim)))\n",
    "model.add(Bidirectional(LSTM(32,return_sequences=True)))\n",
    "# model.add(LSTM(16,return_sequences=False))\n",
    "model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "# model.add(Attention(name='attention_weight'))\n",
    "model.add(Dense(4,activation=\"tanh\",  kernel_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(1,activation=\"tanh\",  kernel_regularizer=regularizers.l1(0.01)))\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.01, clipvalue=0.5)\n",
    "model.compile(optimizer=optimizer,loss=\"mean_squared_error\", metrics=[\"mse\"])\n",
    "model.fit(X_train,Y_train,batch_size=64,epochs=7,validation_split=0.1,verbose=1)\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "# print(f'Evaluate: {model.evaluate(X_test,Y_test, verbose=1)}')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#反标准化\n",
    "def inverse_label(data, width):\n",
    "    l, _ = data.shape\n",
    "    data_trans = np.zeros((l, width))\n",
    "    data_trans[:,-3] = data.reshape((l))\n",
    "    data_trans = scaler.inverse_transform(data_trans)\n",
    "    return data_trans[:,-3]\n",
    "\n",
    "h, _, w = X_train.shape\n",
    "#预测测试集\n",
    "predict_trainY=model.predict(X_train)\n",
    "predict_testY=model.predict(X_test)\n",
    "#反标准化\n",
    "# trainY=scaler.inverse_transform(predict_trainY)\n",
    "testY_real = inverse_label(Y_test[:,np.newaxis], w)\n",
    "testY_predict = inverse_label(predict_testY, w)\n",
    "# testY_real = Y_test\n",
    "# testY_predict = predict_testY\n",
    "\n",
    "\n",
    "#看一看数据形状\n",
    "print(\"Y:\",testY_predict.reshape((-1)),testY_predict.shape)\n",
    "print(\"Y_real:\",testY_real,testY_real.shape)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(testY_predict,\"b\",label=\"Predict\")\n",
    "plt.plot(testY_real,\"r\",label=\"Real\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#看一看数据形状\n",
    "# trainY_predict = inverse_label(predict_trainY, w)\n",
    "# trainY_real = inverse_label(Y_train[:,np.newaxis], w)\n",
    "trainY_predict = predict_trainY\n",
    "trainY_real = Y_train\n",
    "\n",
    "print(\"Y:\",trainY_predict.reshape((-1)),trainY_predict.shape)\n",
    "print(\"Y_real:\",trainY_real,trainY_real.shape)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(trainY_predict,\"b\",label=\"Predict\")\n",
    "plt.plot(trainY_real,\"r\",label=\"Real\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers,Input,optimizers\n",
    "# from tensorflow.keras.layers import Bidirectional\n",
    "# input_shape=Input(shape=(x_train.shape[1],x_train.shape[2]))\n",
    "# lstm1=layers.LSTM(32,return_sequences=1)(input_shape)\n",
    "# print(\"lstm1:\",lstm1.shape)\n",
    "# lstm2=layers.LSTM(64,return_sequences=0)(lstm1)\n",
    "# print(\"lstm2:\",lstm2.shape)\n",
    "# dense1=layers.Dense(64,activation=\"relu\")(lstm2)\n",
    "# print(\"dense:\",dense1.shape)\n",
    "# dropout=layers.Dropout(rate=0.2)(dense1)\n",
    "# print(\"dropout:\",dropout.shape)\n",
    "# ouput_shape=layers.Dense(1,activation=\"relu\")(dropout)\n",
    "# model=tf.keras.Model(input_shape,ouput_shape)\n",
    "# model.compile(loss=\"mean_squared_error\",optimizer=\"Adam\",metrics=[\"mse\"])#mse作为l损失函数，采用Adam作为寻优方式\n",
    "# history=model.fit(x_train,y_train,batch_size=32,epochs=10,validation_split=0.1,verbose=1)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "print(is_cuda)\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ee4d181cff9adcd5efc9b7e40de0ada85f5a4786332094f7b11b4a1f550d203"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
